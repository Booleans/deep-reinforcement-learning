{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor(3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations have an underscore appended to their name. Operations without an underscore are the functional equivalent and create a copy of the tensor with the performed modification, leaving the original tensor untouched.\n",
    "\n",
    "You can also create tensors from Python iterables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1,2,3], [3,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(3,2))\n",
    "b = torch.tensor(n)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that by default we created a 64 bit array. Usually in deep learning double precision is not required and it adds extra performance and memory overhead. Common practice is to use the 32 bit float type, or even the 16 bit float type, which is more than enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(3,2), dtype=np.float32)\n",
    "torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(3,2))\n",
    "torch.tensor(n, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you pass a `dtype` argument into the `torch.tensor` function it expected a `torch.float` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 dimemsional tensor.\n",
    "s = a.sum()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the actual Python value of a 0 dimensional tensor using .item().\n",
    "s.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Tensors\n",
    "\n",
    "To convert from CPU to GPU, there is a tensor method `to(device)`, that creates a copy of the tensor to a specified device (CPU or GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca = a.to('cuda')\n",
    "ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "\n",
    "Even with transparent GPU support, all of this dancing with tensors isn't worth\n",
    "bothering with without one \"killer feature\"â€”the automatic computation of gradients. There are two approaches to how your gradients are calculated.\n",
    "\n",
    "* **Static graph**: In this method, you need to define your calculations in advance and it won't be possible to change them later. The graph will be processed and optimized by the DL library before any computation is made.\n",
    "\n",
    "* **Dynamic graph**: You don't need to define your graph in advance exactly as it will be executed, you just need to execute operations that you want to use for data transformation on your actual data. During this, the library will record the order of the operations performed, and when you ask it to calculate gradients, it will unroll its history of operations, accumulating the gradients of the network parameters. \n",
    "\n",
    "#### Tensors and Gradients\n",
    "\n",
    "PyTorch tensors have a built-in gradient calculation and tracking system, so all you need to do is convert the data into tensors and perform computations using the tensor methods and functions provided by `torch`. There are several attributes related to gradients that every tensor has:\n",
    "\n",
    "* `grad`: A property that holds a tensor of the same shape containing computed gradients.\n",
    "\n",
    "* `is_leaf`: True if this tensor was constructed by the user and False if the object is a result of function transformation.\n",
    "\n",
    "* `requires_grad`: True if this tensor requires gradients to be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1.0, 1.0], requires_grad=True)\n",
    "v2 = torch.tensor([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum = v1 + v2\n",
    "v_res = (v_sum*2).sum()\n",
    "v_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have added both vectors element-wise, double every element, and then summed them together. The results is a 0 dimensional tensor with the value 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.is_leaf, v2.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.is_leaf, v_res.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad, v2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.requires_grad, v_res.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's tell PyTorch to calculate the gradients of our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res.backward()\n",
    "v1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the `backward` function we asked PyTorch to calculate the numerical derivative of the `v_res` variable with respect to any variable that our graph has. In other words, what influence do small changes to the `v_res` variable have on the rest of the graph. In our particular example, the value of two in the gradients of `v1` means that by increasing any element of `v1` by one, the resulting value of `v_res` will grow by two.\n",
    "\n",
    "As mentioned, PyTorch calculates gradients only for leaf tensors with requirement `grad=True`. Indeed, if we try to check the gradients of `v2`, we get nothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1624,  1.1437, -0.9851, -1.0531,  0.4556], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "l = nn.Linear(2, 5)\n",
    "v = torch.FloatTensor([1, 2])\n",
    "l(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we created a randomly initialized feed-forward layer, with two inputs and 5 outputs, and applied it to our float tensor. All classes in the `torch.nn` packages inherit from the `nn.Module` base class, which you can use to implement your own higher-level NN blocks. You will see how you can do this in the next section, but, for now, let's look at useful methods that all `nn.Module` children provide. They are\n",
    "as follows:\n",
    "\n",
    "* `parameters()`: This function returns an iterator of all variables that require gradient computation (that is, module weights).\n",
    "* `zero_grad()`: This function initializes all gradients of all parameters to zero.\n",
    "* `to(device)`: This function moves all module parameters to a given device (CPU or GPU).\n",
    "* `state_dict()`: This function returns the dictionary with all module parameters and is useful for model serialization.\n",
    "* `load_state_dict()`: This function initialized the module with the state dictionary.\n",
    "\n",
    "`Sequential` is a convenient class that allows you to combine other layers into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): Dropout(p=0.3, inplace=False)\n",
       "  (6): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0939, 0.1859, 0.0614, 0.0738, 0.1017, 0.0939, 0.1137, 0.0899, 0.0963,\n",
       "         0.0896]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(torch.FloatTensor([[1, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Layers\n",
    "\n",
    "By subclassing the `nn.Module` class, you can create your own building blocks, which can be stacked together, reused later, and integrated into the PyTorch framework flawlessly. At its core, the `nn.Module` provides quite rich functionality to its children:\n",
    "\n",
    "* It tracks all submodules that the current module includes. For example, your building blocks can have two feed-forward layers used somehow to perform the block's transformation.\n",
    "\n",
    "* It provides functions to deal with all parameters of the registered submodules. You can obtain a full list of the modules parameters (`parameters()` method), zero its gradients (`zero_grads()` method), serialize and deserialize the module (`state_dict()` and `load_state_dict()`) and even perform generic transformations using your own callable (`apply()` method).\n",
    "\n",
    "* It establishes the convention of `Module` application to data. Every module needs to perform its data transformation in the `forward()` method by overriding it. \n",
    "\n",
    "* There are some more functions, such as the ability to register a hook function to tweak modeul transformation or gradients flow, but they are more for advanced use cases.\n",
    "\n",
    "To make our life simpler, when following the preceding convention, the PyTorch authors simplified the creation of modules through careful design and a good dose of Python magic. So, to create a custom module, we usually have to do only two thingsâ€”register submodules and implement the `forward()` method. Let's look at how this can be done for our Sequential example from the previous\n",
    "section, but in a more generic and reusable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
    "        super(OurModule, self).__init__()\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, num_classes),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our module class that inherits ``nn.Module``. In the constructor, we pass three parameters: the input size, the output size, and the optional dropout probability. The first thing we need to do is call the parent's constructor to let it initialize itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    return self.pipe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we must override the `forward` function with our implementation of the data transformation. As our module is a very simple wrapper around other layers, we just need to ask them to transform the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurModule(\n",
      "  (pipe): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "tensor([[0.2745, 0.2745, 0.4509]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = OurModule(num_inputs=2, num_classes=3)\n",
    "v = torch.FloatTensor([[2, 3]])\n",
    "out = net(v)\n",
    "print(net)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final glue - loss functions and optimizers\n",
    "\n",
    "#### Loss Functions\n",
    "\n",
    "Loss functions reside in the `nn` package and are implement as an `nn.Module` subclass. Usually, they accept two arguments: output from the network and desired output. The most commonly used standard loss functions are:\n",
    "\n",
    "* `nn.MSELoss`\n",
    "* `nn.BCELoss` and `nn.BCEWithLogits`: Binary cross-entropy loss. The first version expects a single probability value (usually it's the output of the `Sigmoid` layer), while the second version assumes raw scores as input and applies `Sigmoid` itself. The second is usually more stable and efficient. \n",
    "* `nn.CrossEntropyLoss` and `nn.NLLLoss`: Famous maximum likelihoos criteria that are used in multi-class classification problems. The first version expects raw scores for each class and applies `LogSoftmax` internally, while the second expects to have log probabilities as the input.\n",
    "\n",
    "#### Optimizers\n",
    "\n",
    "The resposibility of the basic optimizer is to take the gradients of model parameters and change these parameters in order to decrease the loss value. In the `torch.optim` package, PyTorch provides lots of popular optimizer implementations and the most widely known are as follows:\n",
    "\n",
    "* SGD: A vanilla stochastic gradient descent algorithm with an optional momentum extension.\n",
    "* RMSprop\n",
    "* Adagrad\n",
    "* Adam\n",
    "\n",
    "On construction, you need to pass an interable of tensors, which will be modified during the optimization process. The usual practice is to pass the result of the `params()` call of the upper level `nn.Module` instance, which will return an interable of all leaf tensors with gradients. Now, let's discuss the common blueprint of a training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x, batch_y in iterate_batches(data, batch_size=32):\n",
    "    batch_x_t = torch.tensor(batch_x)\n",
    "    batch_y_t = torch.tensor(batch_y)\n",
    "    out_t = net(batch_x_t)\n",
    "    loss_t = loss_function(out_y, batch_y_t)\n",
    "    loss_t.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring with TensorBoard\n",
    "\n",
    "DL practitioners have developed a list of things that you should observe during your training, which usually includes the following:\n",
    "\n",
    "* Loss values, which normally consists of several components like base loss and regularization losses. You should monitor both the total loss and the individual components over time.\n",
    "* Results of validation on training and test datasetes.\n",
    "* Statistics about gradients and weights.\n",
    "* Values produced by the network. For example, if you are soliving a classification problem, you definitely want to measure the entropy of predicted class probabilities. In the case of a regression problem, raw predicted values can give tons of data about the training.\n",
    "* Learning rates and other hyperparameters, if they are adjusted over time.\n",
    "\n",
    "\n",
    "#### TesnorBoard 101\n",
    "\n",
    "From the architecture point of view, TensorBoard is a Python web service that you can start on your computer, passing it the directory where your training process will save values to be analyzed. Then, you point your browser to TensorBoard's port (usually `6006`), and it shows you an interactive web interface with values updated in real time. It's nice and convenient, especially when your training is performed on a remote machine somewhere in the cloud.\n",
    "\n",
    "**Plotting Stuff**\n",
    "\n",
    "To give you an impression of how simple tensorboardX is, let's consider a small example that is not related to NNs, but is just about writing stuff into TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "funcs = {'sin': math.sin, 'cos': math.cos, 'tan': math.tan}\n",
    "\n",
    "for angle in range(-360, 360):\n",
    "    angle_rad = angle * math.pi / 180\n",
    "    for name, func in funcs.items():\n",
    "        val = func(angle_rad)\n",
    "        writer.add_scalar(name, val, angle)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**: Tensorboardx is not currently starting on my Windows machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example â€“ GAN on Atari Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "\n",
    "class InputWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, *args):\n",
    "        super(InputWrapper, self).__init__(*args)\n",
    "        assert isinstance(self.observation_space, gym.spaces.Box)\n",
    "        old_space = self.observation_space\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            self.observation(old_space.low),\n",
    "            self.observation(old_space.high),\n",
    "            dtype=np.float32)\n",
    "            \n",
    "    def observation(self, observation):\n",
    "        new_obs = cv2.resize(\n",
    "            observation, (IMAGE_SIZE, IMAGE_Size))\n",
    "        # Transform (210, 160, 3) -> (3, 210, 160)\n",
    "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
    "        return new_obs.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is a wrapper around a Gym game, which includes several transformations.\n",
    "\n",
    "* Resize the input imag efrom 210x160 (standard Atari resolution) to a 64x64 square.\n",
    "* Move the volor plane of the image from the last position to the first, to meet the PyTorch convention of convolution layers that input a tensor with the shape of the channels, height, width.\n",
    "* Cast the image from `bytes` to `float`.\n",
    "\n",
    "The code for the generator and discriminator are included in the book repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
    "    batch = [e.reset() for e in envs]\n",
    "    env_gen = iter(lambda: random.choice(envs), None)\n",
    "    \n",
    "    while True:\n",
    "        e = next(env_gen)\n",
    "        obs, reward, is_done, _ = e.step(e.action_space.sample())\n",
    "        if np.mean(obs) > 0.01:\n",
    "            batch.append(obs)\n",
    "        if len(batch) == batch_size:\n",
    "            # Normalizing input between -1 and 1\n",
    "            batch_np = np.array(batch, dtype=np.float32)\n",
    "            batch_np *= 2.0 / 255.0 - 1.0\n",
    "            yield torch.tensor(batch_np)\n",
    "            batch.clear()\n",
    "        if is_done():\n",
    "            e.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This infinitely samples the environment from the provided array, issues random actions, and remembers observations in the batch list. When the batch becomes the required size, we normalize the image, convert it to a tensor, and yield from the generator. The check for the non-zero mean of the observation is required due to a bug in one of the games to prevent the flickering of an image.\n",
    "\n",
    "Now, let's look at our main function, which prepares models and runs the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--cuda', default=False, action='store_true', help='Enable cuda computation')\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "envs = [\n",
    "    InputWrapper(gym.make(name))\n",
    "    for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')\n",
    "]\n",
    "input_shape = envs[0].observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we process the command-line arguments and create our environment pool, with a wrapper applied. This environment array will be passed to the `iterate_batches` function to generate training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_discr = Discriminator(input_shape=input_shape).to(device)\n",
    "net_gener = Generator(output_shape=input_shape).to(device)\n",
    "\n",
    "objective = nn.BCELess()\n",
    "\n",
    "gen_optimizer = optim.Adam(\n",
    "    params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "dis_optimizer = optim.Adam(\n",
    "    params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Ignite\n",
    "\n",
    "**Ignite Concepts**\n",
    "\n",
    "At a high level, Ignite simplifies the writing of the training loop in PyTorch DL. Earlier in the chapter we saw that the minimal training loop consists of:\n",
    "\n",
    "* Sampling a batch of training data.\n",
    "* Applying a NN to this batch to calculate the loss function - the single value we want to minimize. \n",
    "* Running backpropagation of the loss to get gradients on the network's parameters in respect to the loss.\n",
    "* Asking the optimzer to apply the gradients to the network.\n",
    "* Repeating until we are happy or bored of waiting.\n",
    "\n",
    "The central piece to Ignite is the `Engine` class, which loops over the data source, applying the processing function to the data batch. In addition to that, Ignore offers the abilities to provide functions to be called at specific conditions of the training loop. Those conditions are called `Events` and could be at the:\n",
    "\n",
    "* Beginning/end of the whole training process.\n",
    "* Beginning/end of a training epoch.\n",
    "* Beginning/end of a single batch processing.\n",
    "\n",
    "In addition to that, custom events exist and allow you to specify your function to be called every `N` events, for example, if you want to do some calculations every 100 batches or every second epoch. \n",
    "\n",
    "A very simplistic example of Ignite is shown in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "\n",
    "def training(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = prepare_batch()\n",
    "    y_out = model(x)\n",
    "    loss = loss_fn(y_out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "engine = Engine(training)\n",
    "engine.run(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
